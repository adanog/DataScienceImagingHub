{"cells":[{"cell_type":"markdown","id":"0c814820","metadata":{"id":"0c814820"},"source":["# About the notebook\n","The purpose of this Jupyter Notebook is to use a pre-trained deep learning model to generate class predictions for a given input image.  \n"]},{"cell_type":"markdown","id":"3ad28b6b","metadata":{"id":"3ad28b6b"},"source":["# 00 - Special Instructions for Google Colab Users\n","\n","The following lines of code should be executed only when running your script on Google Colab. This is crucial to leverage the additional features provided by Colab, most notably, the availability of a free GPU.  **If, you're running the code locally, this line can be skipped (GO TO STEP 01 - Loading dependencies) as it pertains specifically to the Colab setup.**\n","\n","## Give access to google drive"]},{"cell_type":"code","execution_count":1,"id":"8060f967","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8060f967","executionInfo":{"status":"ok","timestamp":1729091027695,"user_tz":360,"elapsed":23720,"user":{"displayName":"Haydee Olinca Hernández Aviña","userId":"10682686729776532917"}},"outputId":"ff9c4c2d-7769-4244-f4df-c5bd1d6a3a94"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"37144f95","metadata":{"id":"37144f95"},"source":["## Install Napari"]},{"cell_type":"code","execution_count":2,"id":"e28f5445","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e28f5445","executionInfo":{"status":"ok","timestamp":1729091050840,"user_tz":360,"elapsed":23149,"user":{"displayName":"Haydee Olinca Hernández Aviña","userId":"10682686729776532917"}},"outputId":"9a513034-5f7a-49cf-e202-cddaf091e8c0","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting napari\n","  Downloading napari-0.5.4-py3-none-any.whl.metadata (13 kB)\n","Collecting appdirs>=1.4.4 (from napari)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n","Collecting app-model<0.4.0,>=0.3.0 (from napari)\n","  Downloading app_model-0.3.0-py3-none-any.whl.metadata (3.7 kB)\n","Collecting cachey>=0.2.1 (from napari)\n","  Downloading cachey-0.2.1-py3-none-any.whl.metadata (2.2 kB)\n","Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.10/dist-packages (from napari) (2024.8.30)\n","Requirement already satisfied: dask>=2021.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[array]>=2021.10.0->napari) (2024.8.0)\n","Requirement already satisfied: imageio!=2.22.1,>=2.20 in /usr/local/lib/python3.10/dist-packages (from napari) (2.35.1)\n","Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from napari) (4.23.0)\n","Requirement already satisfied: lazy-loader>=0.2 in /usr/local/lib/python3.10/dist-packages (from napari) (0.4)\n","Collecting magicgui>=0.7.0 (from napari)\n","  Downloading magicgui-0.9.1-py3-none-any.whl.metadata (7.2 kB)\n","Collecting napari-console>=0.0.9 (from napari)\n","  Downloading napari_console-0.1.0-py3-none-any.whl.metadata (5.7 kB)\n","Collecting napari-plugin-engine>=0.1.9 (from napari)\n","  Downloading napari_plugin_engine-0.2.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting napari-svg>=0.1.8 (from napari)\n","  Downloading napari_svg-0.2.0-py3-none-any.whl.metadata (3.6 kB)\n","Collecting npe2>=0.7.6 (from napari)\n","  Downloading npe2-0.7.7-py3-none-any.whl.metadata (3.1 kB)\n","Collecting numpydoc>=0.9.2 (from napari)\n","  Downloading numpydoc-1.8.0-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from napari) (2.2.2)\n","Requirement already satisfied: Pillow>=9.0 in /usr/local/lib/python3.10/dist-packages (from napari) (10.4.0)\n","Collecting pint>=0.17 (from napari)\n","  Downloading Pint-0.24.3-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.10/dist-packages (from napari) (5.9.5)\n","Collecting psygnal>=0.5.0 (from napari)\n","  Downloading psygnal-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n","Requirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from napari) (2.9.2)\n","Requirement already satisfied: pygments>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from napari) (2.18.0)\n","Requirement already satisfied: PyOpenGL>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from napari) (3.1.7)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from napari) (6.0.2)\n","Collecting qtpy>=1.10.0 (from napari)\n","  Downloading QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: scikit-image>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image[data]>=0.19.1->napari) (0.24.0)\n","Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from napari) (1.13.1)\n","Collecting superqt>=0.6.7 (from napari)\n","  Downloading superqt-0.6.7-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: tifffile>=2022.4.8 in /usr/local/lib/python3.10/dist-packages (from napari) (2024.9.20)\n","Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from napari) (0.12.1)\n","Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.10/dist-packages (from napari) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from napari) (4.12.2)\n","Collecting vispy<0.15,>=0.14.1 (from napari)\n","  Downloading vispy-0.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from napari) (1.16.0)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from napari) (1.26.4)\n","Collecting in-n-out>=0.1.5 (from app-model<0.4.0,>=0.3.0->napari)\n","  Downloading in_n_out-0.2.1-py3-none-any.whl.metadata (4.1 kB)\n","Collecting pydantic-compat>=0.1.1 (from app-model<0.4.0,>=0.3.0->napari)\n","  Downloading pydantic_compat-0.1.2-py3-none-any.whl.metadata (8.4 kB)\n","Collecting heapdict (from cachey>=0.2.1->napari)\n","  Downloading HeapDict-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.10.0->dask[array]>=2021.10.0->napari) (8.1.7)\n","Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.10.0->dask[array]>=2021.10.0->napari) (2.2.1)\n","Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.10.0->dask[array]>=2021.10.0->napari) (2024.6.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.10.0->dask[array]>=2021.10.0->napari) (24.1)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.10.0->dask[array]>=2021.10.0->napari) (1.4.2)\n","Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2021.10.0->dask[array]>=2021.10.0->napari) (8.5.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->napari) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->napari) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->napari) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->napari) (0.20.0)\n","Requirement already satisfied: docstring-parser>=0.7 in /usr/local/lib/python3.10/dist-packages (from magicgui>=0.7.0->napari) (0.16)\n","Requirement already satisfied: IPython>=7.7.0 in /usr/local/lib/python3.10/dist-packages (from napari-console>=0.0.9->napari) (7.34.0)\n","Requirement already satisfied: ipykernel>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from napari-console>=0.0.9->napari) (5.5.6)\n","Collecting qtconsole!=4.7.6,!=5.4.2,>=4.5.1 (from napari-console>=0.0.9->napari)\n","  Downloading qtconsole-5.6.0-py3-none-any.whl.metadata (5.0 kB)\n","Requirement already satisfied: build>=1 in /usr/local/lib/python3.10/dist-packages (from npe2>=0.7.6->napari) (1.2.2.post1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from npe2>=0.7.6->napari) (13.9.2)\n","Collecting tomli-w (from npe2>=0.7.6->napari)\n","  Downloading tomli_w-1.1.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from npe2>=0.7.6->napari) (2.0.2)\n","Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from npe2>=0.7.6->napari) (0.12.5)\n","Collecting sphinx>=6 (from numpydoc>=0.9.2->napari)\n","  Downloading sphinx-8.1.3-py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=0.9.2->napari) (0.9.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->napari) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->napari) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->napari) (2024.2)\n","Collecting flexcache>=0.3 (from pint>=0.17->napari)\n","  Downloading flexcache-0.3-py3-none-any.whl.metadata (7.0 kB)\n","Collecting flexparser>=0.3 (from pint>=0.17->napari)\n","  Downloading flexparser-0.3.1-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->napari) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->napari) (2.23.4)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.1->scikit-image[data]>=0.19.1->napari) (3.4)\n","Requirement already satisfied: pooch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image[data]>=0.19.1->napari) (1.8.2)\n","Collecting freetype-py (from vispy<0.15,>=0.14.1->napari)\n","  Downloading freetype_py-2.5.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n","Collecting hsluv (from vispy<0.15,>=0.14.1->napari)\n","  Downloading hsluv-5.0.4-py2.py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: kiwisolver in /usr/local/lib/python3.10/dist-packages (from vispy<0.15,>=0.14.1->napari) (1.4.7)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1->npe2>=0.7.6->napari) (1.2.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask>=2021.10.0->dask[array]>=2021.10.0->napari) (3.20.2)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel>=5.2.0->napari-console>=0.0.9->napari) (0.2.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=5.2.0->napari-console>=0.0.9->napari) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=5.2.0->napari-console>=0.0.9->napari) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=5.2.0->napari-console>=0.0.9->napari) (6.3.3)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython>=7.7.0->napari-console>=0.0.9->napari) (71.0.4)\n","Collecting jedi>=0.16 (from IPython>=7.7.0->napari-console>=0.0.9->napari)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython>=7.7.0->napari-console>=0.0.9->napari) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython>=7.7.0->napari-console>=0.0.9->napari) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython>=7.7.0->napari-console>=0.0.9->napari) (3.0.48)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython>=7.7.0->napari-console>=0.0.9->napari) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython>=7.7.0->napari-console>=0.0.9->napari) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython>=7.7.0->napari-console>=0.0.9->napari) (4.9.0)\n","Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask>=2021.10.0->dask[array]>=2021.10.0->napari) (1.0.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.6.0->scikit-image[data]>=0.19.1->napari) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.6.0->scikit-image[data]>=0.19.1->napari) (2.32.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->napari) (1.16.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from qtconsole!=4.7.6,!=5.4.2,>=4.5.1->napari-console>=0.0.9->napari) (5.7.2)\n","Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (2.1.0)\n","Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (2.0.0)\n","Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (3.1.4)\n","Collecting docutils<0.22,>=0.20 (from sphinx>=6->numpydoc>=0.9.2->napari)\n","  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (2.2.0)\n","Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (2.16.0)\n","Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (0.7.16)\n","Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=6->numpydoc>=0.9.2->napari) (1.4.1)\n","Collecting pyconify>=0.1.4 (from superqt[iconify]>=0.6.1->magicgui>=0.7.0->napari)\n","  Downloading pyconify-0.1.6-py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->npe2>=0.7.6->napari) (3.0.0)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->npe2>=0.7.6->napari) (1.5.4)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython>=7.7.0->napari-console>=0.0.9->napari) (0.8.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1->sphinx>=6->numpydoc>=0.9.2->napari) (3.0.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=5.2.0->napari-console>=0.0.9->napari) (24.0.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->npe2>=0.7.6->napari) (0.1.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython>=7.7.0->napari-console>=0.0.9->napari) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython>=7.7.0->napari-console>=0.0.9->napari) (0.2.13)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.6.0->scikit-image[data]>=0.19.1->napari) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.6.0->scikit-image[data]>=0.19.1->napari) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.6.0->scikit-image[data]>=0.19.1->napari) (2.2.3)\n","Downloading napari-0.5.4-py3-none-any.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading app_model-0.3.0-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Downloading cachey-0.2.1-py3-none-any.whl (6.4 kB)\n","Downloading magicgui-0.9.1-py3-none-any.whl (124 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading napari_console-0.1.0-py3-none-any.whl (9.7 kB)\n","Downloading napari_plugin_engine-0.2.0-py3-none-any.whl (33 kB)\n","Downloading napari_svg-0.2.0-py3-none-any.whl (15 kB)\n","Downloading npe2-0.7.7-py3-none-any.whl (92 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpydoc-1.8.0-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Pint-0.24.3-py3-none-any.whl (301 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading psygnal-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (727 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.4/727.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading superqt-0.6.7-py3-none-any.whl (90 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading vispy-0.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flexcache-0.3-py3-none-any.whl (13 kB)\n","Downloading flexparser-0.3.1-py3-none-any.whl (27 kB)\n","Downloading in_n_out-0.2.1-py3-none-any.whl (19 kB)\n","Downloading pydantic_compat-0.1.2-py3-none-any.whl (13 kB)\n","Downloading qtconsole-5.6.0-py3-none-any.whl (124 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading freetype_py-2.5.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n","Downloading hsluv-5.0.4-py2.py3-none-any.whl (5.3 kB)\n","Downloading tomli_w-1.1.0-py3-none-any.whl (6.4 kB)\n","Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyconify-0.1.6-py3-none-any.whl (18 kB)\n","Installing collected packages: heapdict, appdirs, tomli-w, qtpy, psygnal, napari-plugin-engine, jedi, in-n-out, hsluv, freetype-py, flexparser, flexcache, docutils, cachey, vispy, superqt, sphinx, pyconify, pint, pydantic-compat, numpydoc, napari-svg, qtconsole, npe2, magicgui, app-model, napari-console, napari\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.18.1\n","    Uninstalling docutils-0.18.1:\n","      Successfully uninstalled docutils-0.18.1\n","  Attempting uninstall: sphinx\n","    Found existing installation: Sphinx 5.0.2\n","    Uninstalling Sphinx-5.0.2:\n","      Successfully uninstalled Sphinx-5.0.2\n","Successfully installed app-model-0.3.0 appdirs-1.4.4 cachey-0.2.1 docutils-0.21.2 flexcache-0.3 flexparser-0.3.1 freetype-py-2.5.1 heapdict-1.0.1 hsluv-5.0.4 in-n-out-0.2.1 jedi-0.19.1 magicgui-0.9.1 napari-0.5.4 napari-console-0.1.0 napari-plugin-engine-0.2.0 napari-svg-0.2.0 npe2-0.7.7 numpydoc-1.8.0 pint-0.24.3 psygnal-0.11.1 pyconify-0.1.6 pydantic-compat-0.1.2 qtconsole-5.6.0 qtpy-2.4.1 sphinx-8.1.3 superqt-0.6.7 tomli-w-1.1.0 vispy-0.14.3\n"]}],"source":["!pip install napari"]},{"cell_type":"markdown","id":"d7819107","metadata":{"id":"d7819107"},"source":["## Copy code to current session"]},{"cell_type":"code","execution_count":3,"id":"1d5e9c7e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1d5e9c7e","executionInfo":{"status":"ok","timestamp":1729091051888,"user_tz":360,"elapsed":1054,"user":{"displayName":"Haydee Olinca Hernández Aviña","userId":"10682686729776532917"}},"outputId":"018920fb-0539-4e15-e456-5cd4f171dacc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'image_classification_pytorch'...\n","remote: Enumerating objects: 202, done.\u001b[K\n","remote: Counting objects: 100% (202/202), done.\u001b[K\n","remote: Compressing objects: 100% (121/121), done.\u001b[K\n","remote: Total 202 (delta 112), reused 165 (delta 78), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (202/202), 765.11 KiB | 9.00 MiB/s, done.\n","Resolving deltas: 100% (112/112), done.\n"]}],"source":["!git clone https://github.com/paul-hernandez-herrera/image_classification_pytorch\n","import os\n","workbookDir = \"/content/image_classification_pytorch/\"\n","os.chdir(workbookDir)"]},{"cell_type":"markdown","id":"2d9fa4ea","metadata":{"id":"2d9fa4ea"},"source":["# 01 - Loading dependencies\n","In this notebook, before running any code, there are several libraries and modules that need to be imported to ensure that the notebook runs smoothly. These libraries and modules contain pre-written code that performs specific tasks, such as reading and processing images, defining the UNET model, and training the model."]},{"cell_type":"code","execution_count":4,"id":"d18617ce","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d18617ce","executionInfo":{"status":"ok","timestamp":1729091076976,"user_tz":360,"elapsed":17677,"user":{"displayName":"Haydee Olinca Hernández Aviña","userId":"10682686729776532917"}},"outputId":"82aae1e6-9735-4b5d-d42a-408514002837"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/image_classification_pytorch\n"]}],"source":["import os\n","if 'workbookDir' not in globals():\n","    print('Updating working directory')\n","    workbookDir = os.path.dirname(os.getcwd())\n","    os.chdir(workbookDir)\n","print(os.getcwd())\n","import torch\n","\n","from core_code.predict import PredictClassInteractive\n","from core_code.util.show_image import show_images_predicted_class_interactive\n","\n","#allow reloading the functions updates\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","source":["# 01.5 - Create stacks from to channels, run only if necessary\n","\n","The model require one single image from 2 channels in tif format. This cell is create single images from to brightfield and fluorescence image to a single one."],"metadata":{"id":"A4l3g1wM2-0v"},"id":"A4l3g1wM2-0v"},{"cell_type":"code","source":["pip install Pillow numpy tifffile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCUUp7evuxay","executionInfo":{"status":"ok","timestamp":1729053860914,"user_tz":360,"elapsed":3344,"user":{"displayName":"Haydee Olinca Hernández Aviña","userId":"10682686729776532917"}},"outputId":"17ae23d7-cc61-4bf7-ec0a-3ba2fb98d094"},"id":"VCUUp7evuxay","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (2024.9.20)\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tifffile as tiff\n","\n","# Paths to the directories\n","campo_claro_dir = '/content/drive/MyDrive/20241016_ImageClassifierFocus/Dataset/Canal campo claro/'\n","fluorescencia_dir = '/content/drive/MyDrive/20241016_ImageClassifierFocus/Dataset/Canal fluorescencia'\n","\n","# Get all TIFF files from both directories\n","campo_claro_files = sorted([os.path.join(campo_claro_dir, f) for f in os.listdir(campo_claro_dir) if f.endswith('.ome.tif')])\n","fluorescencia_files = sorted([os.path.join(fluorescencia_dir, f) for f in os.listdir(fluorescencia_dir) if f.endswith('.ome.tif')])\n","\n","# Check that we have the same number of files in both directories\n","if len(campo_claro_files) != len(fluorescencia_files):\n","    raise ValueError(\"Number of images in 'Canal Campo Claro' and 'Canal Fluorescencia' must match.\")\n","\n","# Process each pair of files\n","for i, (file1_path, file2_path) in enumerate(zip(campo_claro_files, fluorescencia_files)):\n","    # Read the images using tifffile\n","    image1 = tiff.imread(file1_path)\n","    image2 = tiff.imread(file2_path)\n","\n","    # Ensure both images have the same size\n","    if image1.shape != image2.shape:\n","        raise ValueError(f\"Images {file1_path} and {file2_path} must be the same size to concatenate them as channels.\")\n","\n","    # Convert to appropriate shape if necessary\n","    if image1.ndim == 3 and image1.shape[0] > 1:\n","        image1 = image1.transpose(1, 2, 0)  # Change from (C, H, W) to (H, W, C)\n","    if image2.ndim == 3 and image2.shape[0] > 1:\n","        image2 = image2.transpose(1, 2, 0)\n","\n","    # Stack the images along a new channel dimension\n","    concatenated = np.stack((image1, image2), axis=-1)  # Shape will be (H, W, C, 2)\n","\n","    # Convert to shape (C, H, W) for TIFF\n","    concatenated = np.moveaxis(concatenated, -1, 0)  # Now shape is (2, H, W)\n","\n","    # Save the concatenated image\n","    output_path = f'/content/drive/MyDrive/20241016_ImageClassifierFocus/Dataset/mergeChannels/concatenated_image_{i+1}.tif'\n","    tiff.imwrite(output_path, concatenated)\n","\n","    # print(f\"Concatenated image saved at {output_path} with shape: {concatenated.shape}\")\n"],"metadata":{"id":"-yLsnuzXwg6q"},"id":"-yLsnuzXwg6q","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"91655c7c","metadata":{"id":"91655c7c"},"source":["# 02 - Setting required parameters\n","In this section, users can specify the necessary parameters to predict the segmentation mask for a given input image. The following parameters are required:\n","\n","**Model path**: The path to the trained model that will be used for segmentation prediction.\n","\n","**Input path**: The path to the folder containing the input images, or the path to a single 'tif' image.\n","\n","**Output path (Optional)**: The path where the output of the network will be saved. If you do not provide an output path, the algorithm will automatically create a folder named 'output' in the same folder as the input images, and save the predictions there.\n","\n","**Device**: The device that will be used to perform the operations.\n","\n","**Do not run this cell**"]},{"cell_type":"code","execution_count":null,"id":"0d63c199","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139,"referenced_widgets":["571b3adcd41d4b07a2d0bab77f6dbd55","eb11184f16b24fd5b932c06aeb41dc18","b377531b60ac4f7e93aad027187c63a6","7841ac2ac4ff48bfa225611c1a186237","95a079e3be6f4c209076e98a7cafd6dc","4c715d3c972f4b86b4eecdd99cff541e","2f8bf9cb9d9040f6a3d3690780c17beb","8e1ba322fa3c46fb9a04e22e19e80381","3ab40a40e0704b30b6c1565431105d86","183e13718bb64c6d81a20df3561bad16","3215763ae9054d5a98363114ed45c095","b646631c1e6740f2bc45542b3d814dba"]},"id":"0d63c199","executionInfo":{"status":"ok","timestamp":1729053925162,"user_tz":360,"elapsed":201,"user":{"displayName":"Haydee Olinca Hernández Aviña","userId":"10682686729776532917"}},"outputId":"d30cd002-43c9-4a63-db35-4e7ba849dbc4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Text(value='', description='Model path:', layout=Layout(flex='1 1 auto', width='auto'), placeholder='Insert pa…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"571b3adcd41d4b07a2d0bab77f6dbd55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Text(value='', description='Folder path:', layout=Layout(flex='1 1 auto', width='auto'), placeholder='Insert p…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7841ac2ac4ff48bfa225611c1a186237"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Text(value='', description='Output path:', layout=Layout(flex='1 1 auto', width='auto'), placeholder='Insert p…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f8bf9cb9d9040f6a3d3690780c17beb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Device: ', options=(('CPU', 'cpu'),), style=DescriptionStyle(description_width='initial'…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"183e13718bb64c6d81a20df3561bad16"}},"metadata":{}}],"source":["predict_interactive = PredictClassInteractive()"]},{"cell_type":"markdown","id":"c1bf4f4d","metadata":{"id":"c1bf4f4d"},"source":["# 03 - Do the prediction\n","This line of code allows you to predict the images using the trained deep learning model."]},{"cell_type":"code","execution_count":null,"id":"316bbf4d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"316bbf4d","executionInfo":{"status":"ok","timestamp":1729056814105,"user_tz":360,"elapsed":26534,"user":{"displayName":"Haydee Olinca Hernández Aviña","userId":"10682686729776532917"}},"outputId":"c1e5590b-a4ab-468e-83bd-ec34e0ffbfe6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/image_classification_pytorch/core_code/util/deeplearning_util.py:133: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(model_path, map_location= device)\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/20241016_ImageClassifierFocus/Models/.best_model_e14.pth\n"]},{"output_type":"stream","name":"stderr","text":["/content/image_classification_pytorch/core_code/predict.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  img = torch.tensor(input_img).unsqueeze(0).to(device=device)\n"]},{"output_type":"stream","name":"stdout","text":["concatenated_image_1.tif  DONE\n","concatenated_image_2.tif  DONE\n","concatenated_image_3.tif  DONE\n","concatenated_image_4.tif  DONE\n","concatenated_image_5.tif  DONE\n","concatenated_image_6.tif  DONE\n","concatenated_image_7.tif  DONE\n","concatenated_image_8.tif  DONE\n","concatenated_image_9.tif  DONE\n","concatenated_image_10.tif  DONE\n","concatenated_image_11.tif  DONE\n","concatenated_image_12.tif  DONE\n","concatenated_image_13.tif  DONE\n","concatenated_image_14.tif  DONE\n","concatenated_image_15.tif  DONE\n","concatenated_image_16.tif  DONE\n","concatenated_image_17.tif  DONE\n","concatenated_image_18.tif  DONE\n","concatenated_image_19.tif  DONE\n","concatenated_image_20.tif  DONE\n","concatenated_image_21.tif  DONE\n","concatenated_image_22.tif  DONE\n","concatenated_image_23.tif  DONE\n","concatenated_image_24.tif  DONE\n","concatenated_image_25.tif  DONE\n","concatenated_image_26.tif  DONE\n","concatenated_image_27.tif  DONE\n","concatenated_image_28.tif  DONE\n","concatenated_image_29.tif  DONE\n","concatenated_image_30.tif  DONE\n","concatenated_image_31.tif  DONE\n","concatenated_image_32.tif  DONE\n","concatenated_image_33.tif  DONE\n","concatenated_image_34.tif  DONE\n","concatenated_image_35.tif  DONE\n","concatenated_image_36.tif  DONE\n","concatenated_image_37.tif  DONE\n","concatenated_image_38.tif  DONE\n","concatenated_image_39.tif  DONE\n","concatenated_image_40.tif  DONE\n","concatenated_image_41.tif  DONE\n","concatenated_image_42.tif  DONE\n","concatenated_image_43.tif  DONE\n","concatenated_image_44.tif  DONE\n","concatenated_image_45.tif  DONE\n","concatenated_image_46.tif  DONE\n","concatenated_image_47.tif  DONE\n","concatenated_image_48.tif  DONE\n","concatenated_image_49.tif  DONE\n","concatenated_image_50.tif  DONE\n","concatenated_image_51.tif  DONE\n","concatenated_image_52.tif  DONE\n","concatenated_image_53.tif  DONE\n","concatenated_image_54.tif  DONE\n","concatenated_image_55.tif  DONE\n","concatenated_image_56.tif  DONE\n","concatenated_image_57.tif  DONE\n","concatenated_image_58.tif  DONE\n","concatenated_image_59.tif  DONE\n","concatenated_image_60.tif  DONE\n","concatenated_image_61.tif  DONE\n","concatenated_image_62.tif  DONE\n","concatenated_image_63.tif  DONE\n","concatenated_image_64.tif  DONE\n","concatenated_image_65.tif  DONE\n","concatenated_image_66.tif  DONE\n","concatenated_image_67.tif  DONE\n","concatenated_image_68.tif  DONE\n","concatenated_image_69.tif  DONE\n","concatenated_image_70.tif  DONE\n","concatenated_image_71.tif  DONE\n","concatenated_image_72.tif  DONE\n","concatenated_image_73.tif  DONE\n","concatenated_image_74.tif  DONE\n","concatenated_image_75.tif  DONE\n","concatenated_image_76.tif  DONE\n","concatenated_image_77.tif  DONE\n","concatenated_image_78.tif  DONE\n","concatenated_image_79.tif  DONE\n","concatenated_image_80.tif  DONE\n"]}],"source":["output = predict_interactive.run()"]},{"cell_type":"markdown","id":"a65367e7","metadata":{"id":"a65367e7"},"source":["# 04 - Visualization\n","This sections provides an opportunity for the user to inspect and visually analyze the results of the segmentation prediction. This step is important to ensure that the predicted segmentations are appropriate and accurate."]},{"cell_type":"code","execution_count":5,"id":"aa66d979","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"aa66d979","executionInfo":{"status":"error","timestamp":1729091251969,"user_tz":360,"elapsed":227,"user":{"displayName":"Haydee Olinca Hernández Aviña","userId":"10682686729776532917"}},"outputId":"4a4acbee-5aba-4bc3-abef-ec7789152ca8"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'output' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-8285a9c72034>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_images_predicted_class_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted_class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"]}],"source":["show_images_predicted_class_interactive(output[\"inputs\"], output[\"predicted_class\"])"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"571b3adcd41d4b07a2d0bab77f6dbd55":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextView","continuous_update":true,"description":"Model path:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_eb11184f16b24fd5b932c06aeb41dc18","placeholder":"Insert path here","style":"IPY_MODEL_b377531b60ac4f7e93aad027187c63a6","value":"/content/drive/MyDrive/20241016_ImageClassifierFocus/Models/.best_model_e14.pth"}},"eb11184f16b24fd5b932c06aeb41dc18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"1 1 auto","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"auto"}},"b377531b60ac4f7e93aad027187c63a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"7841ac2ac4ff48bfa225611c1a186237":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextView","continuous_update":true,"description":"Folder path:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_95a079e3be6f4c209076e98a7cafd6dc","placeholder":"Insert path here","style":"IPY_MODEL_4c715d3c972f4b86b4eecdd99cff541e","value":"/content/drive/MyDrive/20241016_ImageClassifierFocus/Dataset/mergeChannels/"}},"95a079e3be6f4c209076e98a7cafd6dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"1 1 auto","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"auto"}},"4c715d3c972f4b86b4eecdd99cff541e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"2f8bf9cb9d9040f6a3d3690780c17beb":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextView","continuous_update":true,"description":"Output path:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_8e1ba322fa3c46fb9a04e22e19e80381","placeholder":"Insert path here","style":"IPY_MODEL_3ab40a40e0704b30b6c1565431105d86","value":""}},"8e1ba322fa3c46fb9a04e22e19e80381":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"1 1 auto","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"auto"}},"3ab40a40e0704b30b6c1565431105d86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"183e13718bb64c6d81a20df3561bad16":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["CPU"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Device: ","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_3215763ae9054d5a98363114ed45c095","style":"IPY_MODEL_b646631c1e6740f2bc45542b3d814dba"}},"3215763ae9054d5a98363114ed45c095":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b646631c1e6740f2bc45542b3d814dba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}}}}},"nbformat":4,"nbformat_minor":5}